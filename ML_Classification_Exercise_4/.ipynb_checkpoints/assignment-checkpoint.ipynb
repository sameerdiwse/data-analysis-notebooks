{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c03b46f-c555-4cf3-9437-83742df60430",
   "metadata": {},
   "source": [
    "### Titanic Survival Prediction\n",
    "\n",
    "You are a data scientist / AI engineer working on a binary classification problem to predict the survival of passengers from the Titanic crash. You have been provided with a dataset named **`\"titanic.csv\"`** which includes various features of passengers to predict whether they survived or not. The dataset comprises the following columns:\n",
    "\n",
    "- `passenger_id:` The unique identifier for each passenger.\n",
    "- `name:` The name of the passenger.\n",
    "- `p_class:` The passenger class (1 = 1st class, 2 = 2nd class, 3 = 3rd class).\n",
    "- `sex:` The gender of the passenger.\n",
    "- `age:` The age of the passenger.\n",
    "- `sib_sp:` The number of siblings or spouses the passenger had aboard the Titanic.\n",
    "- `parch:` The number of parents or children the passenger had aboard the Titanic.\n",
    "- `ticket:` The ticket number of the passenger.\n",
    "- `fare:` The fare the passenger paid for the ticket.\n",
    "- `cabin:` The cabin number where the passenger stayed.\n",
    "- `embarked:` The port where the passenger boarded the Titanic (C = Cherbourg; Q = Queenstown; S = Southampton).\n",
    "- `survived:` Whether the passenger survived (1) or not (0).\n",
    "\n",
    "Your task is to use this dataset to build and evaluate a `Gaussian Naive Bayes` model to predict whether a passenger survived based on their features. You will also evaluate the model's performance using precision, recall, and other classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69af457-1cf7-45b2-88b2-dd0a1e801c56",
   "metadata": {},
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8160e63-5083-44f1-8d52-f21d4579733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98288af3-582f-42d7-ae63-241aeff7809b",
   "metadata": {},
   "source": [
    "### Task 1: Data Preparation and Exploration\n",
    "\n",
    "1. Import the data from the `\"titanic.csv\"` file and store it in a variable df.\n",
    "2. Display the number of rows and columns in the dataset.\n",
    "3. Display the first few rows of the dataset to get an overview.\n",
    "4. Check for any missing values in the dataset.\n",
    "5. Drop columns that do not add much value `(passenger_id, name, sib_sp, parch, ticket, cabin, embarked)`.\n",
    "6. Visualize the distribution of the target variable `survived` and `p_class` using a bar chart.\n",
    "7. Visualize the distribution of `sex` using a pie chart (percentage).\n",
    "8. Visualize the distribution of `age` and `fare` using histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3afaa1a-9c2e-440e-afe8-e42c81539af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the data from the \"titanic.csv\" file and store it in a variable df\n",
    "\n",
    "\n",
    "# Step 2: Display the number of rows and columns in the dataset\n",
    "\n",
    "\n",
    "# Step 3: Display the first few rows of the dataset to get an overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4123d602-5c2f-4524-9c89-1435807d0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Check for any missing values in the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50929a5c-a225-4b96-9bba-dbf75eb709f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Drop columns that do not add much value (passenger_id, name, sib_sp, parch, ticket, cabin, embarked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51bf3e9-0cef-448f-b45e-0f39e95369be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Visualize the distribution\n",
    "\n",
    "#'survived'\n",
    "\n",
    "\n",
    "# 'p_class'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff252510-d2e8-4b22-a5c4-e08475c915b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Visualize the distribution of 'sex' using a pie chart (percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44b2d4f2-841a-430c-8072-ddb2d9a4d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Visualize the distribution of 'age' using a histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "488ce36d-53d6-4f63-94e1-8ef1e716b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Visualize the distribution of 'fare' using a histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65491a7f-98a5-481e-b380-23b517fb4c0f",
   "metadata": {},
   "source": [
    "### Task 2: Data Preprocessing\n",
    "\n",
    "1. Fill in missing values in the `age and fare` columns with their median values.\n",
    "2. Encode the sex column using one-hot encoding.\n",
    "3. Standardize the fare column using StandardScaler.\n",
    "4. Select the features `(p_class, sex, age, fare)` and the target variable `(survived)` for modeling.\n",
    "5. Split the dataset into training and testing sets with a test size of 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21fe2d7c-8174-4270-8d14-ac2e76adcd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fill in missing values in the 'age' and 'fare' columns with their median values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a48f5a8c-f4f0-455a-8d69-0031924269d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Encode the 'sex' column using one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca8f6401-9194-4396-844c-f2bd98bfc30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Standardize the 'fare' column using StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9776e74b-3d2c-40f7-b41b-35a6ac59933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Select the features and target variable for modeling\n",
    "\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets with a test size of 30%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcca5a-13f3-4d47-a59f-d19465087c08",
   "metadata": {},
   "source": [
    "### Task 3: Model Training Using Gaussian Naive Bayes\n",
    "\n",
    "1. Initialize and train a `Gaussian Naive Bayes` model using the training data.\n",
    "2. Make predictions on the test set using the trained model.\n",
    "3. Evaluate the model using a classification report and print the report.\n",
    "4. Visualize the confusion matrix for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de744d68-1193-4939-a5a9-fdeac54a84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize and train a Gaussian Naive Bayes model using the training data\n",
    "\n",
    "\n",
    "# Step 2: Make predictions on the test set using the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff0c4579-8bff-4e90-adde-eda3e584c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Evaluate the model using a classification report and print the report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e60a4df5-c6a9-475d-a1a7-a1af3384a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize the confusion matrix for the model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
